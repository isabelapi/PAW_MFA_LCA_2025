{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45845759",
   "metadata": {},
   "source": [
    "# Adding Functional Units from Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50c3c25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flodym as fd\n",
    "import flodym.export as fde\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c951e5d",
   "metadata": {},
   "source": [
    "### add all flow data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac97539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take variable derived in mfa?!\n",
    "flow_definitions = [  # MODIFY ALL dim_letters\n",
    "    # inflow\n",
    "    fd.FlowDefinition(\n",
    "        from_process_name=\"sysenv\",\n",
    "        to_process_name=\"ind_ww\",\n",
    "        dim_letters=(\"t\", \"c\", \"s\", \"x\", \"r\"),\n",
    "    ),\n",
    "    fd.FlowDefinition(\n",
    "        from_process_name=\"sysenv\",\n",
    "        to_process_name=\"dom_ww\",\n",
    "        dim_letters=(\"t\", \"c\", \"s\", \"x\", \"r\"),\n",
    "    ),\n",
    "    #  first treatment\n",
    "    fd.FlowDefinition(\n",
    "        from_process_name=\"ind_ww\",\n",
    "        to_process_name=\"dec_tre\",\n",
    "        dim_letters=(\"t\", \"c\", \"s\", \"x\", \"r\", \"g\"),\n",
    "    ),\n",
    "    #   fd.FlowDefinition(from_process_name='ind_ww', to_process_name='nof', dim_letters=('t', 'c', 's', 'x', 'r', 'g')),\n",
    "    fd.FlowDefinition(\n",
    "        from_process_name=\"dom_ww\",\n",
    "        to_process_name=\"sec_tre\",\n",
    "        dim_letters=(\"t\", \"c\", \"s\", \"x\", \"r\"),\n",
    "    ),\n",
    "    fd.FlowDefinition(\n",
    "        from_process_name=\"dec_tre\",\n",
    "        to_process_name=\"sec_tre\",\n",
    "        dim_letters=(\"t\", \"c\", \"s\", \"x\", \"r\", \"g\"),\n",
    "    ),\n",
    "    fd.FlowDefinition(\n",
    "        from_process_name=\"dec_tre\",\n",
    "        to_process_name=\"wtr_dis\",\n",
    "        dim_letters=(\"t\", \"c\", \"s\", \"x\", \"r\", \"g\"),\n",
    "    ),\n",
    "    fd.FlowDefinition(\n",
    "        from_process_name=\"dec_tre\",\n",
    "        to_process_name=\"oxi_com\",\n",
    "        dim_letters=(\"c\", \"x\", \"r\", \"g\"),\n",
    "    ),\n",
    "    # second treatment\n",
    "    #  fd.FlowDefinition(from_process_name='sec_tre', to_process_name='nof', dim_letters=('t', 'c', 's', 'x', 'r', 'g')),\n",
    "    #  fd.FlowDefinition(from_process_name='sec_tre', to_process_name='aop', dim_letters=('t', 'c', 's', 'x', 'r', 'g')),\n",
    "    #   fd.FlowDefinition(from_process_name='sec_tre', to_process_name='o3', dim_letters=('t', 'c', 's', 'x', 'r', 'g')),\n",
    "    #   fd.FlowDefinition(from_process_name='sec_tre', to_process_name='gac', dim_letters=('t', 'c', 's', 'x', 'r', 'g')),\n",
    "    fd.FlowDefinition(\n",
    "        from_process_name=\"sec_tre\",\n",
    "        to_process_name=\"qua_tre\",\n",
    "        dim_letters=(\"t\", \"c\", \"s\", \"x\", \"r\", \"g\"),\n",
    "    ),\n",
    "    fd.FlowDefinition(\n",
    "        from_process_name=\"sec_tre\",\n",
    "        to_process_name=\"sldg_sep\",\n",
    "        dim_letters=(\"t\", \"c\", \"s\", \"r\"),\n",
    "    ),\n",
    "    fd.FlowDefinition(\n",
    "        from_process_name=\"sec_tre\",\n",
    "        to_process_name=\"oxi_com\",\n",
    "        dim_letters=(\"c\", \"s\", \"x\", \"r\"),\n",
    "    ),\n",
    "    # quaternary treatment\n",
    "    #    fd.FlowDefinition(from_process_name='nof', to_process_name='wtr_dis', dim_letters=('t', 'c', 's', 'x', 'r', 'g')),\n",
    "    #    fd.FlowDefinition(from_process_name='aop', to_process_name='wtr_dis', dim_letters=('t', 'c', 's', 'x', 'r', 'g')),\n",
    "    #    fd.FlowDefinition(from_process_name='o3', to_process_name='wtr_dis', dim_letters=('t', 'c', 's', 'x', 'r', 'g')),\n",
    "    #    fd.FlowDefinition(from_process_name='gac', to_process_name='wtr_dis', dim_letters=('t', 'c', 's', 'x', 'r', 'g')),\n",
    "    fd.FlowDefinition(\n",
    "        from_process_name=\"qua_tre\",\n",
    "        to_process_name=\"wtr_dis\",\n",
    "        dim_letters=(\"t\", \"c\", \"s\", \"x\", \"r\", \"g\"),\n",
    "    ),\n",
    "    #    fd.FlowDefinition(from_process_name='gac', to_process_name='inc', dim_letters=('t', 'c', 's', 'x', 'r', 'g')),\n",
    "    fd.FlowDefinition(\n",
    "        from_process_name=\"qua_tre\",\n",
    "        to_process_name=\"inc\",\n",
    "        dim_letters=(\"t\", \"c\", \"s\", \"x\", \"r\", \"g\"),\n",
    "    ),\n",
    "    #    fd.FlowDefinition(from_process_name='nof', to_process_name='oxi_com', dim_letters=('t', 'c', 's', 'x', 'r', 'g')),\n",
    "    #    fd.FlowDefinition(from_process_name='aop', to_process_name='oxi_com', dim_letters=('t', 'c', 's', 'x', 'r', 'g')),\n",
    "    #    fd.FlowDefinition(from_process_name='o3', to_process_name='oxi_com', dim_letters=('t', 'c', 's', 'x', 'r', 'g')),\n",
    "    fd.FlowDefinition(\n",
    "        from_process_name=\"qua_tre\",\n",
    "        to_process_name=\"oxi_com\",\n",
    "        dim_letters=(\"c\", \"x\", \"r\", \"g\"),\n",
    "    ),\n",
    "    # intermediate use\n",
    "    fd.FlowDefinition(\n",
    "        from_process_name=\"wtr_dis\",\n",
    "        to_process_name=\"irr\",\n",
    "        dim_letters=(\"t\", \"c\", \"s\", \"x\", \"r\"),\n",
    "    ),\n",
    "    fd.FlowDefinition(\n",
    "        from_process_name=\"wtr_dis\",\n",
    "        to_process_name=\"riv\",\n",
    "        dim_letters=(\"t\", \"c\", \"s\", \"x\", \"r\"),\n",
    "    ),\n",
    "    fd.FlowDefinition(\n",
    "        from_process_name=\"sldg_sep\",\n",
    "        to_process_name=\"inc\",\n",
    "        dim_letters=(\"t\", \"c\", \"s\", \"x\", \"r\"),\n",
    "    ),\n",
    "    fd.FlowDefinition(\n",
    "        from_process_name=\"sldg_sep\",\n",
    "        to_process_name=\"fer\",\n",
    "        dim_letters=(\"t\", \"c\", \"s\", \"x\", \"r\"),\n",
    "    ),\n",
    "    # final discharge\n",
    "    fd.FlowDefinition(\n",
    "        from_process_name=\"irr\",\n",
    "        to_process_name=\"soi\",\n",
    "        dim_letters=(\"t\", \"c\", \"s\", \"x\", \"r\", \"g\"),\n",
    "    ),\n",
    "    fd.FlowDefinition(\n",
    "        from_process_name=\"fer\",\n",
    "        to_process_name=\"soi\",\n",
    "        dim_letters=(\"t\", \"c\", \"s\", \"x\", \"r\", \"g\"),\n",
    "    ),\n",
    "    fd.FlowDefinition(\n",
    "        from_process_name=\"inc\",\n",
    "        to_process_name=\"lan\",\n",
    "        dim_letters=(\"t\", \"c\", \"s\", \"x\", \"r\", \"g\"),\n",
    "    ),\n",
    "    fd.FlowDefinition(\n",
    "        from_process_name=\"inc\",\n",
    "        to_process_name=\"co2\",\n",
    "        dim_letters=(\"t\", \"c\", \"s\", \"x\", \"r\", \"g\"),\n",
    "    ),\n",
    "    fd.FlowDefinition(\n",
    "        from_process_name=\"inc\",\n",
    "        to_process_name=\"oxi_com\",\n",
    "        dim_letters=(\"t\", \"c\", \"s\", \"x\", \"r\", \"g\"),\n",
    "    ),\n",
    "    # outflow\n",
    "    fd.FlowDefinition(\n",
    "        from_process_name=\"oxi_com\",\n",
    "        to_process_name=\"sysenv\",\n",
    "        dim_letters=(\"t\", \"c\", \"s\", \"x\", \"r\", \"g\"),\n",
    "    ),\n",
    "    fd.FlowDefinition(\n",
    "        from_process_name=\"co2\",\n",
    "        to_process_name=\"sysenv\",\n",
    "        dim_letters=(\"t\", \"c\", \"s\", \"x\", \"r\", \"g\"),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700ae5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit will be tons (m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5b8954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV files for all flow definitions\n",
    "\n",
    "\n",
    "def import_flows(base_path):\n",
    "    imported_flows = []\n",
    "    # Ensure base_path ends with a separator\n",
    "    if not base_path.endswith((\"\\\\\", \"/\")):\n",
    "        base_path = base_path + \"\\\\\"\n",
    "    for flow_def in flow_definitions:\n",
    "        # Create variable name: from_process_name_to_process_name\n",
    "        var_name = f\"{flow_def.from_process_name}_{flow_def.to_process_name}\"\n",
    "        # Create file name: from_process_name__to_process_name.csv (double underscore)\n",
    "        file_name = f\"{flow_def.from_process_name}__{flow_def.to_process_name}.csv\"\n",
    "        file_path = base_path + file_name\n",
    "\n",
    "        # Read CSV and assign to variable\n",
    "        df = pd.read_csv(file_path)\n",
    "        globals()[var_name] = df\n",
    "        imported_flows.append(df)\n",
    "    print(f\"Imported {len(imported_flows)} flows\")\n",
    "    return imported_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54cebe47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 24 flows\n"
     ]
    }
   ],
   "source": [
    "# actually import\n",
    "\n",
    "imported_flows = import_flows(\n",
    "    \"C:/Users/Asus/Documents/repositories/PAW_MFA_LCA_2025/MFA/Data/mfa_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1406a0",
   "metadata": {},
   "source": [
    "### extract information per scenario and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24e70eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate per year and scenario\n",
    "years = [2020, 2035, 2045]\n",
    "scenarios = [\"high_env_pol\", \"low_env_pol\"]\n",
    "all_activities = pd.DataFrame()\n",
    "\n",
    "# Get flow names from flow_definitions to match with imported_flows\n",
    "flow_names = [f\"{fd.from_process_name}_{fd.to_process_name}\" for fd in flow_definitions]\n",
    "\n",
    "# drop all rows with 0 values and process each flow\n",
    "for idx, flow in enumerate(imported_flows):\n",
    "    flow_name = flow_names[idx] if idx < len(flow_names) else f\"flow_{idx}\"\n",
    "\n",
    "    # Remove rows with 0 values (create a copy to avoid modifying original)\n",
    "    flow_filtered = flow[flow[\"value\"] != 0].copy()\n",
    "\n",
    "    # Skip if no data after filtering\n",
    "    if len(flow_filtered) == 0:\n",
    "        continue\n",
    "\n",
    "    # Check which columns exist\n",
    "    has_time = \"time\" in flow_filtered.columns\n",
    "    has_scenario = \"scenario\" in flow_filtered.columns\n",
    "\n",
    "    # Create pivot table based on available columns\n",
    "    if has_time and has_scenario:\n",
    "        # Sum values by time and scenario\n",
    "        pivot = flow_filtered.groupby([\"time\", \"scenario\"])[\"value\"].sum().reset_index()\n",
    "        pivot = pivot.rename(columns={\"time\": \"year\"})\n",
    "        # Ensure we have the right columns\n",
    "        if (\n",
    "            \"year\" not in pivot.columns\n",
    "            or \"scenario\" not in pivot.columns\n",
    "            or \"value\" not in pivot.columns\n",
    "        ):\n",
    "            pivot = pd.DataFrame(columns=[\"year\", \"scenario\", \"value\"])\n",
    "    elif has_time:\n",
    "        # Sum values by time only, then expand to all scenarios\n",
    "        pivot = flow_filtered.groupby(\"time\")[\"value\"].sum().reset_index()\n",
    "        pivot = pivot.rename(columns={\"time\": \"year\"})\n",
    "        # Expand to all scenarios with same value\n",
    "        expanded = []\n",
    "        for _, row in pivot.iterrows():\n",
    "            for scenario in scenarios:\n",
    "                expanded.append(\n",
    "                    {\"year\": row[\"year\"], \"scenario\": scenario, \"value\": row[\"value\"]}\n",
    "                )\n",
    "        if expanded:\n",
    "            pivot = pd.DataFrame(expanded)\n",
    "        else:\n",
    "            pivot = pd.DataFrame(columns=[\"year\", \"scenario\", \"value\"])\n",
    "    elif has_scenario:\n",
    "        # Sum values by scenario only, then expand to all years\n",
    "        pivot = flow_filtered.groupby(\"scenario\")[\"value\"].sum().reset_index()\n",
    "        pivot = pivot[[\"scenario\", \"value\"]]\n",
    "        # Expand to all years with same value\n",
    "        expanded = []\n",
    "        for _, row in pivot.iterrows():\n",
    "            for year in years:\n",
    "                expanded.append(\n",
    "                    {\"year\": year, \"scenario\": row[\"scenario\"], \"value\": row[\"value\"]}\n",
    "                )\n",
    "        if expanded:\n",
    "            pivot = pd.DataFrame(expanded)\n",
    "        else:\n",
    "            pivot = pd.DataFrame(columns=[\"year\", \"scenario\", \"value\"])\n",
    "    else:\n",
    "        # No time or scenario - sum all values, then expand to all combinations\n",
    "        total_value = flow_filtered[\"value\"].sum()\n",
    "        # Create all combinations\n",
    "        expanded = []\n",
    "        for year in years:\n",
    "            for scenario in scenarios:\n",
    "                expanded.append(\n",
    "                    {\"year\": year, \"scenario\": scenario, \"value\": total_value}\n",
    "                )\n",
    "        if expanded:\n",
    "            pivot = pd.DataFrame(expanded)\n",
    "        else:\n",
    "            pivot = pd.DataFrame(columns=[\"year\", \"scenario\", \"value\"])\n",
    "\n",
    "    # Final validation: ensure pivot has required columns\n",
    "    required_cols = [\"year\", \"scenario\", \"value\"]\n",
    "    missing_cols = [col for col in required_cols if col not in pivot.columns]\n",
    "\n",
    "    # Skip if pivot is empty or missing required columns\n",
    "    if len(pivot) == 0 or len(missing_cols) > 0:\n",
    "        continue\n",
    "\n",
    "    # Filter to only specified years and scenarios\n",
    "    try:\n",
    "        pivot = pivot[pivot[\"year\"].isin(years) & pivot[\"scenario\"].isin(scenarios)]\n",
    "    except KeyError as e:\n",
    "        # If we still get a KeyError, skip this flow\n",
    "        print(f\"Warning: Skipping flow {flow_name} due to missing column: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Add flow name column\n",
    "    pivot[\"flow\"] = flow_name\n",
    "\n",
    "    # Reorder columns\n",
    "    pivot = pivot[[\"flow\", \"year\", \"scenario\", \"value\"]]\n",
    "\n",
    "    all_activities = pd.concat([all_activities, pivot], ignore_index=True)\n",
    "\n",
    "all_activities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4334831b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of Empty DataFrame\n",
       "Columns: []\n",
       "Index: []>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_activities.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06417aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# match the names of inventory activities with the names of the flows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brightway",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
